
# PaperTracker example config.
# Run: paper-tracker --config config/default.yml search

# runtime domain
log:
  level: INFO
  to_file: true
  dir: log

# storage domain
storage:
  enabled: true
  db_path: database/papers.db  # Relative path (from working directory) or absolute path (starts with /)
  content_storage_enabled: true  # save full paper content (default: true)
  keep_arxiv_version: false  # false: 2601.21922, true: 2601.21922v1

# search domain - Optional global scope applied to every query.
# Field keys must be uppercase: TITLE/ABSTRACT/AUTHOR/JOURNAL/CATEGORY
# Operator keys must be uppercase: AND/OR/NOT
#
# scope:
#   CATEGORY:
#     OR: [cs.CV]

queries:
  - NAME: 视频及图像压缩
    OR:
      - Image Compression
      - Video Compression
  - NAME: LIC 端到端
    OR:
      - Neural Video Compression
      - Learned Video Compression
      - End-to-end Video
  - NAME: 视频质量指标
    OR:
      - Video Quality Assessment
      - Perceptual Quality Assessment
  - NAME: VSR 视频超分辨率
    OR:
      - Video Super Resolution
      - VSR
      - Video Restoration

search:
  max_results: 3              # max paper count for each query

  # multi round fetch
  pull_every: 7               # Strict time window, unit: day
  fill_enabled: true         # Allow fill with paper outside the strict time window
  max_lookback_days: 30       # Max length for fill window, -1 as infinite
  max_fetch_items: 125        # Max count for item tried to fetch at a time, -1 as infinite
  fetch_batch_size: 25        # Fetch count for each round

# output domain
output:
  base_dir: output/              # Output root directory
  formats: [console, json, markdown, html]             # Output formats: console, json, markdown, html (can select multiple)

  # Markdown export configuration
  markdown:
    template_dir: template/markdown/
    document_template: document.md       # Document-level template
    paper_template: paper.md             # Paper-level template
    paper_separator: "\n\n---\n\n"       # Separator between papers

  # HTML export configuration
  html:
    template_dir: template/html/scholar/
    document_template: document.html
    paper_template: paper.html

# llm domain
llm:
  enabled: true                          # Enable/disable LLM translation features
  provider: openai-compat                 # Provider type (currently only this)
  api_key_env: LLM_API_KEY                # Environment variable for API key
  timeout: 30                             # Request timeout (seconds)
  target_lang: zh                         # Target language (zh/en/ja/ko/fr/de/es)
  temperature: 0.0                        # Sampling temperature (0.0 = deterministic)
  max_tokens: 1000                        # Maximum response tokens (increased for summary)
  max_workers: 3                          # Parallel translation workers

  # Feature selection
  # You can choose one of three modes:
  # 1. Translation only: enable_translation=true, enable_summary=false
  # 2. Summary only: enable_translation=false, enable_summary=true
  # 3. Both: enable_translation=true, enable_summary=true
  enable_translation: true                # Enable abstract translation
  enable_summary: true                    # Enable paper summary (TLDR, motivation, method, result, conclusion)
                                          # Default: false (to control API costs)

  # Retry configuration (for handling timeouts and transient errors)
  max_retries: 3                          # Maximum retry attempts (0 to disable)
  retry_base_delay: 1.0                   # Base delay for exponential backoff (seconds)
  retry_max_delay: 10.0                   # Maximum delay between retries (seconds)
  retry_timeout_multiplier: 1.0           # Timeout multiplier per retry (1.0 = no change)

  # base_url: https://api.openai.com        # API base URL
  # model: gpt-4o-mini                      # Model identifier

  base_url: https://api.deepseek.com
  model: deepseek-chat
# Provider-specific configuration examples:
#
# OpenAI GPT-4o-mini (recommended for cost):
# llm:
#   enabled: true
#   base_url: https://api.openai.com
#   model: gpt-4o-mini
#
# DeepSeek (very cost-effective):
# llm:
#   enabled: true
#   base_url: https://api.deepseek.com
#   model: deepseek-chat
#
# SiliconFlow (free tier available):
# llm:
#   enabled: true
#   base_url: https://api.siliconflow.cn
#   model: Qwen/Qwen2.5-7B-Instruct
